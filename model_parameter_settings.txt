random_state_new = 969

sklearn = 1.1.1
xgboost = 1.5.2
numpy = 1.20.3
pandas = 1.4.1
seaborn = 0.11.2
matplotlib = 3.5.1


LR
LogisticRegression(
    penalty='l2',
    *,
    dual=False,
    tol=0.0001,
    C=1.0,
    fit_intercept=True,
    intercept_scaling=1,
    class_weight=None,
    random_state=None,
    solver='liblinear',
    max_iter=100,
    multi_class='auto',
    verbose=0,
    warm_start=False,
    n_jobs=None,
    l1_ratio=None,
)

GBM
GradientBoostingClassifier(
    *, 
    loss="log_loss", 
    learning_rate=0.1, 
    n_estimators=100, 
    subsample=1.0, 
    criterion="friedman_mse", 
    min_samples_split=2, 
    min_samples_leaf=1, 
    min_weight_fraction_leaf=0.0, 
    max_depth=3, 
    min_impurity_decrease=0.0, 
    init=None, 
    random_state=random_state_new, 
    max_features=None, 
    verbose=0, 
    max_leaf_nodes=None, 
    warm_start=False, 
    validation_fraction=0.1, 
    n_iter_no_change=None, 
    tol=1e-4, 
    ccp_alpha=0.0
)

XGB
XGBClassifier(
    base_score=0.5,
    booster='gbtree',
    colsample_bylevel=1,
    colsample_bynode=1,
    colsample_bytree=1,
    gamma=0,
    gpu_id=-1,
    importance_type='gain',
    interaction_constraints='',
    learning_rate=0.300000012,
    max_delta_step=0,
    max_depth=2,
    min_child_weight=1,
    missing=nan,
    monotone_constraints='()',
    n_estimators=100,
    n_jobs=8,
    num_parallel_tree=1,
    reg_alpha=0,
    reg_lambda=1,
    scale_pos_weight=1,
    subsample=1,
    tree_method='exact',
    validate_parameters=1,
    verbosity=None
)

RF
RandomForestClassifier(
    n_estimators=10, 
    *, 
    criterion="gini", 
    max_depth=3, 
    min_samples_split=12, 
    min_samples_leaf=1, 
    min_weight_fraction_leaf=0.0, 
    max_features="sqrt", 
    max_leaf_nodes=None, 
    min_impurity_decrease=0.0, 
    bootstrap=True, 
    oob_score=False, 
    n_jobs=None, 
    random_state=random_state_new, 
    verbose=0, 
    warm_start=False, 
    class_weight=None, 
    ccp_alpha=0.0, 
    max_samples=None
)

NB
GaussianNB(*, 
    priors=None, 
    var_smoothing=1e-9
)

DT
DecisionTreeClassifier(*, 
    criterion="gini", 
    splitter="best", 
    max_depth=None, 
    min_samples_split=2, 
    min_samples_leaf=1, 
    min_weight_fraction_leaf=0.25, 
    max_features=None, 
    random_state=random_state_new, 
    max_leaf_nodes=None, 
    min_impurity_decrease=0.0, 
    class_weight=None, 
    ccp_alpha=0.0
)